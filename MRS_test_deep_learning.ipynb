{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRS test deep learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOeervH2WBHqT85neUNWXOr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madhurika1292/ANALYSIS-AND-PREDICTION-ON-RETURNS-ON-AGRICULTURE-INVESTMENT/blob/master/MRS_test_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kebVJZRumkQ5"
      },
      "source": [
        "pip install surprise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDWqFOY_gdvY"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import surprise\n",
        "import seaborn as sns\n",
        "from sklearn import naive_bayes\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import precision_score, recall_score, precision_recall_curve,f1_score, fbeta_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, make_scorer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from surprise import SVD\n",
        "from textblob import TextBlob\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
        "\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Bidirectional, LSTM, BatchNormalization, Dropout\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import random\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ2AT1qwg0bE"
      },
      "source": [
        "# Importing dataset from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/Drugscom')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UuQDHrSg2ql"
      },
      "source": [
        "#Loading data\n",
        "Drugscom_train=pd.read_csv('/content/gdrive/My Drive/Drugscom/Drugscom_train.csv')\n",
        "Drugscom_test=pd.read_csv('/content/gdrive/My Drive/Drugscom/Drugscom_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOPne5hog4t0"
      },
      "source": [
        "# Dropping null values\n",
        "Drugscom_train = Drugscom_train.dropna(axis=0)\n",
        "Drugscom_test = Drugscom_test.dropna(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0-hXUhcg6e_"
      },
      "source": [
        "#Changing the \"Unnamed: 0\" column to uniqueId as it represents the unique id of the drugs\n",
        "Drugscom_train=Drugscom_train.drop('Unnamed: 0', axis='columns')\n",
        "Drugscom_test=Drugscom_test.drop('Unnamed: 0', axis='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yqUvbV1N0_z"
      },
      "source": [
        "Drugscom_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1yNm3Xdg9eF"
      },
      "source": [
        "#Drugscom_train=Drugscom_train.drop(Drugscom_train[(Drugscom_train['rating'] > 4.0) & (Drugscom_train['rating'] < 6.0)].index)\n",
        "#Drugscom_test=Drugscom_test.drop(Drugscom_test[(Drugscom_test['rating'] > 4.0) & (Drugscom_test['rating'] < 6.0)].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMtjWZXjg_59"
      },
      "source": [
        "#Drugscom_train['sentiment'] = np.where(Drugscom_train['rating'] >= 7, 1, 0)\n",
        "#Drugscom_test['sentiment'] = np.where(Drugscom_test['rating'] >= 7, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9SGuCIAhAgr"
      },
      "source": [
        "def specific_condition_data(df,condition):\n",
        "  \n",
        "  return df[df['condition']==condition]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDnJBVbZhDCG"
      },
      "source": [
        "training_data=specific_condition_data(Drugscom_train,'Anxiety')\n",
        "testing_data=specific_condition_data(Drugscom_test,'Anxiety')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dxtriQFMuUr"
      },
      "source": [
        "pol = lambda x: TextBlob(x).sentiment.polarity\n",
        "sub = lambda x: TextBlob(x).sentiment.subjectivity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo4Kt8xaMylB"
      },
      "source": [
        "training_data['polarity'] = training_data[\"clean_review\"].apply(pol)\n",
        "training_data['subjectivity'] = training_data[\"clean_review\"].apply(sub)\n",
        "testing_data['polarity'] = testing_data[\"clean_review\"].apply(pol)\n",
        "testing_data['subjectivity'] = testing_data[\"clean_review\"].apply(sub)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A6GGmrjPvHT"
      },
      "source": [
        "training_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nkXIgpROnQg"
      },
      "source": [
        "def sentiments(polarity):\n",
        " if (polarity >= 0) :\n",
        "   return 1\n",
        " elif polarity < 0:\n",
        "   return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aERhQjjO0NZ"
      },
      "source": [
        "# Add sentiments to the data\n",
        "training_data[\"sentiment\"] = training_data[\"polarity\"].apply(sentiments)\n",
        "testing_data[\"sentiment\"] = testing_data[\"polarity\"].apply(sentiments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT1llZikhEdy"
      },
      "source": [
        "X_train=training_data.clean_review\n",
        "y_train=training_data.sentiment\n",
        "X_test=testing_data.clean_review\n",
        "y_test=testing_data.sentiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJlyjdIIhGyr"
      },
      "source": [
        "cv = CountVectorizer(max_features = 8000, ngram_range = (4, 4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xvXbd5ihIaT"
      },
      "source": [
        "X_train_cv=cv.fit_transform(X_train)\n",
        "X_test_cv=cv.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goNDYlCW3d0v"
      },
      "source": [
        "X_train_cv.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfo7dNEaIdIb"
      },
      "source": [
        "def grid_best_parameter(X_train_cv,y_train,X_test_cv,y_test):\n",
        "\n",
        "  #Report to carry out the metrices and scores of different models\n",
        "  report_table = [[]]\n",
        "  \n",
        "  #creating parameter\n",
        "\n",
        "  #C= [1.0, 0.5, 0.1]\n",
        "  C=np.logspace(-50, 50, 100)\n",
        "  alpha= [0.01, 0.1, 0.5, 1.0, 10.0]\n",
        "  k_range = list(range(1, 16))\n",
        "  \n",
        "  \n",
        "\n",
        "  # creating pipeline\n",
        "  pipe_lr=Pipeline([('clf' , LogisticRegression(random_state=42))])\n",
        "  pipe_mnb=Pipeline([('clf', MultinomialNB())])\n",
        "  pipe_bnb=Pipeline([('clf', BernoulliNB())])\n",
        "  pipe_svc = Pipeline([('clf', LinearSVC())])\n",
        "  pipe_dtc = Pipeline([('clf', DecisionTreeClassifier())])\n",
        "  pipe_rfc = Pipeline([('clf', RandomForestClassifier(random_state=42))])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #creating parameter\n",
        "\n",
        "  param_lr =[{'clf__penalty': ['l1', 'l2'],\n",
        "\t\t          'clf__C': C,\n",
        "\t\t          'clf__solver': ['liblinear','lbfgs']}] \n",
        "\n",
        "  param_mnb=[{'clf__alpha': alpha}]\n",
        "\n",
        "  param_bnb=[{'clf__alpha': alpha}]\n",
        "  param_svc = {'clf__C':np.arange(0.01,100,10)}\n",
        "  param_dtc = {'clf__criterion':['gini','entropy'],'clf__max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\n",
        "  param_rfc = { \n",
        "    'clf__n_estimators': [200, 500],\n",
        "    'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'clf__max_depth' : [4,5,6,7,8],\n",
        "    'clf__criterion' :['gini', 'entropy']\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # creating gridsearch\n",
        "\n",
        "  grid_lr=GridSearchCV(estimator=pipe_lr,param_grid=param_lr,scoring='accuracy',cv=10,n_jobs=-1)\n",
        "  grid_mnb=GridSearchCV(estimator=pipe_mnb,param_grid=param_mnb,cv=10,verbose=True, n_jobs=-1)\n",
        "  grid_bnb=GridSearchCV(estimator=pipe_bnb,param_grid=param_bnb,cv=10,verbose=True, n_jobs=-1)\n",
        "  grid_svc = GridSearchCV(estimator=pipe_svc,param_grid=param_svc,cv=10,return_train_score=True, n_jobs=1)\n",
        "  grid_dtc = GridSearchCV(estimator=pipe_dtc,param_grid=param_dtc,cv=10, n_jobs=1)\n",
        "  grid_rfc = GridSearchCV(estimator=pipe_rfc,param_grid=param_rfc,cv=10, n_jobs=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #listing pipelines\n",
        "\n",
        "  grid=[grid_lr, grid_mnb, grid_bnb, grid_svc,grid_dtc, grid_rfc]\n",
        "\n",
        "  #dictionary of pipelines and models\n",
        "\n",
        "  grid_dict={0: 'Logistic Regression', 1: 'Multi Nomial NB', 2: 'Bernoulli NB', 3:'Linear SVC', 4:'DecisionTreeClassifier', 5:'RandomForestClassifier'}\n",
        "\n",
        "  # fitting grid search \n",
        "\n",
        "  print('Performing model optimizations...')\n",
        "  best_accuracy = 0.0\n",
        "  best_model = 0\n",
        "  best_grid = ''\n",
        "\n",
        "  for i, g in enumerate(grid):\n",
        "    print('\\nEstimator: %s' % grid_dict[i])\t\n",
        "    # Fit grid search\t\n",
        "    g.fit(X_train_cv, y_train)\n",
        "    # Best params\n",
        "    #print('Best params: %s' % g.best_params_)\n",
        "    # Best training data accuracy\n",
        "    #print('Best training accuracy: %.3f' % g.best_score_)\n",
        "    # Predict on train data with best params\n",
        "    train_prediction = g.predict(X_train_cv)\n",
        "    # Predict on test data with best params\n",
        "    prediction = g.predict(X_test_cv)\n",
        "    # Test data accuracy of model with best params\n",
        "    #print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, prediction))\n",
        "    try:\n",
        "      #calculate roc_auc_score for training data\n",
        "      roc_auc_score_train=roc_auc_score(train_prediction, y_train)\n",
        "\n",
        "      #calculate roc_auc_score for testing data\n",
        "      roc_auc_score_test=roc_auc_score(prediction, y_test)\n",
        "\n",
        "      #calculate RMSE, MSE\n",
        "      from math import sqrt\n",
        "      rmse_score_test= sqrt(mean_squared_error(y_test, prediction))\n",
        "      mse_score_test= mean_squared_error(y_test,prediction)\n",
        "\n",
        "\n",
        "      #calculate f1_score,precision,recall\n",
        "      from sklearn.metrics import precision_score, f1_score, recall_score\n",
        "\n",
        "\n",
        "    except ValueError:\n",
        "      pass\n",
        "   \n",
        "    # Track best (highest test accuracy) model\n",
        "    report_table = report_table+ [[grid_dict[i], g.best_params_, g.score(X_train_cv, y_train), g.score(X_test_cv, y_test), roc_auc_score_train, roc_auc_score_test,rmse_score_test,mse_score_test,precision_score(y_test,prediction),f1_score(y_test,prediction),recall_score(y_test,prediction)]]  \n",
        "    if accuracy_score(y_test, prediction) > best_accuracy:\n",
        "      best_accuracy = accuracy_score(y_test, prediction)\n",
        "      best_model = g\n",
        "      best_grid = i\n",
        "  #print('\\nClassifier with best test set accuracy: %s' % grid_dict[best_grid])\n",
        "  #print('\\nAccuracy score:%s' % best_accuracy)\n",
        "  report_table.pop(0)\n",
        "  report = pd.DataFrame(report_table,columns = ['Model name', 'Model parameter', 'Train accuracy', 'Test accuracy', 'Train auc score', 'Test auc score','RMSE score','MSE score','Precision','F1_score','Recall'])\n",
        "  return report\n",
        "\n",
        "\n",
        "#https://www.kdnuggets.com/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-3.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgIv3Fguj8DE"
      },
      "source": [
        "report=grid_best_parameter(X_train_cv,y_train,X_test_cv,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWDAaZjrwcqz"
      },
      "source": [
        "report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THNjA08WV0p3"
      },
      "source": [
        "#references\n",
        "https://www.kaggle.com/sociopath00/random-forest-using-gridsearchcv"
      ]
    }
  ]
}